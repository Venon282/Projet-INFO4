{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "info = p.get_host_api_info_by_index(0)\n",
    "num_devices = info.get('deviceCount')\n",
    "\n",
    "print(\"Available audio input devices:\")\n",
    "for i in range(num_devices):\n",
    "    device_info = p.get_device_info_by_host_api_device_index(0, i)\n",
    "    if device_info.get('maxInputChannels') > 0:\n",
    "        print(f\"Device {i}: {device_info.get('name')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1: recording sound and passing it as a .wav file to the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1 : recording the sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec():\n",
    "    import pyaudio\n",
    "    import wave\n",
    "\n",
    "    CHUNK = 512\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 48000\n",
    "    RECORD_SECONDS = 10\n",
    "    WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # print the available devices\n",
    "    info = p.get_host_api_info_by_index(0)\n",
    "    num_devices = info.get('deviceCount')\n",
    "    for i in range(num_devices):\n",
    "        if (p.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "            print(f\"Input Device id {i} - {p.get_device_info_by_host_api_device_index(0, i).get('name')}\")\n",
    "\n",
    "    device_id = int(input(\"Select the device id: \"))\n",
    "\n",
    "    print(f\"Recording from {p.get_device_info_by_host_api_device_index(0, device_id).get('name')} for {RECORD_SECONDS} seconds...\")\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    input_device_index=device_id,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Recording complete.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "    print(f\"Exported audio as {WAVE_OUTPUT_FILENAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path ='tf_lite_model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape: \", input_details[0]['shape'])\n",
    "print(\"Input Type: \", input_details[0]['dtype'])\n",
    "print(\"Input Shape: \", output_details[0]['shape'])\n",
    "print(\"Input Type: \", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    n_frames=120\n",
    "    audio, sample_rate = librosa.load(file, res_type='kaiser_fast') \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    #++\n",
    "    frames = np.array_split(mfccs_features.T, n_frames)\n",
    "    features = np.concatenate(frames, axis=0)\n",
    "    \n",
    "    # Compute the mean of each feature across frames\n",
    "    mean_features = np.mean(features, axis=0)                                \n",
    "                                    \n",
    "    \n",
    "    return mean_features  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_array = features_extractor('output.wav')\n",
    "print(wav_array.shape)\n",
    "new_arr = wav_array.reshape((1, 40, 1))\n",
    "print(new_arr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], new_arr)\n",
    "interpreter.invoke()\n",
    "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "max = np.max(tflite_model_predictions)\n",
    "print(np.argmax(tflite_model_predictions))\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model predicts this song is probably done by a bird from the species of  melodia\n"
     ]
    }
   ],
   "source": [
    "def print_prediction_result():\n",
    "    species = \"unknown\"\n",
    "    if np.argmax(tflite_model_predictions) == 0:\n",
    "        species = \"bewickii\"\n",
    "    elif np.argmax(tflite_model_predictions) == 1:\n",
    "        species = \"polyglottos\"\n",
    "    elif np.argmax(tflite_model_predictions) == 2:\n",
    "        species = \"migratorius\"\n",
    "    elif np.argmax(tflite_model_predictions) == 3:\n",
    "        species = \"melodia\"\n",
    "    elif np.argmax(tflite_model_predictions) == 4:\n",
    "        species = \"cardinalis\"\n",
    "    print (\"the model predicts this song is probably done by a bird from the species of \", species)\n",
    "\n",
    "print_prediction_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction():\n",
    "    rec()\n",
    "    wav_array = features_extractor('output.wav')\n",
    "    new_arr = wav_array.reshape((1, 40, 1))\n",
    "    interpreter = tf.lite.Interpreter(model_path ='tf_lite_model.tflite')\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    interpreter.set_tensor(input_details[0]['index'], new_arr)\n",
    "    interpreter.invoke()\n",
    "    tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "    species = \"unknown\"\n",
    "    if np.argmax(tflite_model_predictions) == 0:\n",
    "        species = \"bewickii\"\n",
    "    elif np.argmax(tflite_model_predictions) == 1:\n",
    "        species = \"polyglottos\"\n",
    "    elif np.argmax(tflite_model_predictions) == 2:\n",
    "        species = \"migratorius\"\n",
    "    elif np.argmax(tflite_model_predictions) == 3:\n",
    "        species = \"melodia\"\n",
    "    elif np.argmax(tflite_model_predictions) == 4:\n",
    "        species = \"cardinalis\"\n",
    "    print (\"the model predicts this song is probably done by a bird from the species of \", species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Device id 6 - STM32 AUDIO Streaming in FS Mod: USB Audio (hw:1,0)\n",
      "Input Device id 15 - pulse\n",
      "Input Device id 19 - default\n",
      "Recording from STM32 AUDIO Streaming in FS Mod: USB Audio (hw:1,0) for 10 seconds...\n",
      "Recording complete.\n",
      "Exported audio as output.wav\n",
      "the model predicts this song is probably done by a bird from the species of  melodia\n"
     ]
    }
   ],
   "source": [
    "run_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model predicts this song is probably done by a bird from the species of  melodia\n"
     ]
    }
   ],
   "source": [
    "print_prediction_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2 (ADVANCED) passing sound and dealing with it in real-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "\n",
    "# Set parameters for recording\n",
    "duration = 60  # seconds\n",
    "fs = 48000  # sampling rate\n",
    "device = 6  # device id for recording (id 6 is for the current testing settings)\n",
    "global sp\n",
    "sp = False #boolean to keep in check the number of times a surpass of amplitude is detected\n",
    "\n",
    "# Define function to print \"passed\" when amplitude goes over a certain level\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    global sp\n",
    "    amplitude = np.abs(indata).max()\n",
    "    if amplitude > 0.25 and sp == False:\n",
    "        sp = True\n",
    "        print(\"passed\")\n",
    "    elif amplitude < 0.25 and sp == True:\n",
    "        sp = False\n",
    "    return None\n",
    "\n",
    "# Start recording\n",
    "print(\"Recording...\")\n",
    "with sd.InputStream(channels=1, samplerate=fs, device=device, callback=audio_callback):\n",
    "    sd.sleep(int(duration * 1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asder = 55"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
